{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca073aa5-9f61-4187-87e5-ded6ae9da786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 12:51:08.645: Failed to load module \"canberra-gtk-module\"\n"
     ]
    }
   ],
   "source": [
    "%gui wx\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#####################\n",
    "# Import of utils.py functions\n",
    "#####################\n",
    "# Required to get utils.py and access its functions\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('.')\n",
    "from utils import loadFSL, FSLeyesServer, mkdir_no_exist, interactive_MCQ\n",
    "\n",
    "os.environ[\"DIPY_HOME\"] = \"/home/jovyan/Data\"\n",
    "\n",
    "\n",
    "#############################\n",
    "# Loading fsl and freesurfer within Neurodesk\n",
    "# You can find the list of available other modules by clicking on the \"Softwares\" tab on the left\n",
    "#############################\n",
    "import lmod\n",
    "await lmod.purge(force=True)\n",
    "await lmod.load('fsl/6.0.7.4')\n",
    "await lmod.load('freesurfer/7.4.1')\n",
    "await lmod.list()\n",
    "\n",
    "####################\n",
    "# Setup FSL path\n",
    "####################\n",
    "loadFSL()\n",
    "\n",
    "###################\n",
    "# Load all relevant libraries for the lab\n",
    "##################\n",
    "import fsl.wrappers\n",
    "from fsl.wrappers import fslmaths\n",
    "\n",
    "import mne_nirs\n",
    "import nilearn\n",
    "from nilearn.datasets import fetch_development_fmri\n",
    "\n",
    "import mne\n",
    "import mne_nirs\n",
    "import dipy\n",
    "from dipy.data import fetch_bundles_2_subjects, read_bundles_2_subjects\n",
    "import xml.etree.ElementTree as ET\n",
    "import os.path as op\n",
    "import nibabel as nib\n",
    "import glob\n",
    "\n",
    "import ants\n",
    "\n",
    "import openneuro\n",
    "from mne.datasets import sample\n",
    "from mne_bids import BIDSPath, read_raw_bids, print_dir_tree, make_report\n",
    "\n",
    "\n",
    "# Useful imports to define the direct download function below\n",
    "import requests\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# FSL function wrappers which we will call from python directly\n",
    "from fsl.wrappers import fast, bet\n",
    "from fsl.wrappers.misc import fslroi\n",
    "from fsl.wrappers import flirt\n",
    "\n",
    "# General purpose imports to handle paths, files etc\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325abb6e-c9fd-40f2-96c0-865d93294e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:51:24: Debug: Adding duplicate image handler for 'Windows bitmap file'\n",
      "12:51:24: Debug: Adding duplicate animation handler for '1' type\n",
      "12:51:24: Debug: Adding duplicate animation handler for '2' type\n",
      "12:51:24: Debug: Adding duplicate image handler for 'Windows bitmap file'\n",
      "12:51:24: Debug: Adding duplicate animation handler for '1' type\n",
      "12:51:24: Debug: Adding duplicate animation handler for '2' type\n",
      "\n",
      "(ipykernel_launcher.py:1373): Gtk-CRITICAL **: 12:51:25.545: gtk_window_resize: assertion 'height > 0' failed\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# Start FSLeyes (very neat tool to visualize MRI data of all sorts) within Python\n",
    "################\n",
    "fsleyesDisplay = FSLeyesServer()\n",
    "fsleyesDisplay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76dbcbb-2593-4978-84bd-726929e97cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "dataset_id = \"ds000171\"\n",
    "bids_root = \"./ds000171\"  # Directory to store the downloaded dataset\n",
    "# Path to the 'derivatives' directory for processed data\n",
    "deriv_root = os.path.join(bids_root, 'derivatives')\n",
    "\n",
    "# Create a directory for preprocessed data (e.g., 'preprocessed_data')\n",
    "preproc_root = os.path.join(deriv_root, 'preprocessed_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27260a5-68e3-4732-bc69-d7e36a98d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create the target directory if it does not exist\n",
    "if not os.path.exists(bids_root):\n",
    "    os.makedirs(bids_root)\n",
    "\n",
    "# Download the raw data from OpenNeuro into the target directory\n",
    "#openneuro.download(dataset=dataset_id, target_dir= bids_root)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6803a6b3-e058-4884-a99c-bd11457e9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(preproc_root):\n",
    "    os.makedirs(preproc_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e17a849d-cae4-4c85-9ec0-1e9e00efe69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories created for processed data in ./ds000171/derivatives/preprocessed_data\n"
     ]
    }
   ],
   "source": [
    "subjects = [d for d in os.listdir(bids_root) if d.startswith('sub-con')]\n",
    "# Loop over all subjects and create directories for each subject's processed data\n",
    "for subject in subjects:\n",
    "    subject_dir = os.path.join(preproc_root, subject)\n",
    "\n",
    "    # Create subdirectories for anatomical and functional data\n",
    "    os.makedirs(os.path.join(subject_dir, 'anat'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(subject_dir, 'func'), exist_ok=True)\n",
    "\n",
    "print(f\"Directories created for processed data in {preproc_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e2858da-162d-4784-b3a7-9c31102c7e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oui\n"
     ]
    }
   ],
   "source": [
    "\n",
    "subjects = [d for d in os.listdir(bids_root) if d.startswith('sub-con')]\n",
    "anatomical_path = op.join(bids_root, subjects[0], 'anat', '{}_T1w.nii.gz'.format(subjects[0]))\n",
    "\n",
    "# Check if the anatomical file exists before calling BET\n",
    "if not os.path.exists(anatomical_path):\n",
    "    print(f\"Error: Anatomical file not found: {anatomical_path}\")\n",
    "else : \n",
    "    print(\"oui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0b7df63-ec80-4cdc-ad1d-9f7b92d3108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#________________________________ ANATOMICAL PREPROCESSING ____________________________________________\n",
    "subjects = [d for d in os.listdir(bids_root) if d.startswith('sub-con')]\n",
    "def get_skull_stripped_anatomical(bids_root, preproc_root, subject, robust=False):\n",
    "    \"\"\"\n",
    "    Function to perform skull-stripping (removing the skull around the brain).\n",
    "    This is a simple wrapper around the brain extraction tool (BET) in FSL's suite\n",
    "    It assumes data to be in the BIDS format (which we will cover in the following weeks).\n",
    "    The method also saves the brain mask which was used to extract the brain.\n",
    "\n",
    "    The brain extraction is conducted only on the T1w of the participant.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bids_root: string\n",
    "        The root of the BIDS directory\n",
    "    preproc_root: string\n",
    "        The root of the preprocessed data, where the result of the brain extraction will be saved.\n",
    "    subject_id: string\n",
    "        Subject ID, the subject on which brain extraction should be conducted.\n",
    "    robust: bool\n",
    "        Whether to conduct robust center estimation with BET or not. Default is False.\n",
    "    \"\"\"\n",
    "    anatomical_path = op.join(bids_root, subject, 'anat', '{}_T1w.nii.gz'.format(subject))\n",
    "    betted_brain_path = op.join(preproc_root, subject, 'anat', '{}_T1w'.format(subject))\n",
    "    os.system('bet {} {} -m {}'.format(anatomical_path, betted_brain_path, '-R' if robust else ''))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for sub in tqdm(subjects) : \n",
    "    #get_skull_stripped_anatomical(bids_root, preproc_root, sub, robust = True)\n",
    "\n",
    "#print(\"Done with BET.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "958e129d-e8f9-4776-999d-647a1acd7f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_01 = 'sub-control01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7d0d19b-fbd3-4f5c-9064-949b145a294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_skull_stripped_anatomical(bids_root, preproc_root, subject_01, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e4fefec-2d9a-4113-b618-7128d8612143",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(op.join(preproc_root, subject_01, 'anat', '{}_T1w.nii.gz'.format(subject_01)))\n",
    "fsleyesDisplay.load(resulting_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f5b2e12-7e9f-4c4a-adfd-fc277eb783dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#______________________TISSUE SEGMENTATION_______________\n",
    "\n",
    "anatomical_path = op.join(bids_root, subject_01, 'anat', '{}_T1w.nii.gz'.format(subject_01))\n",
    "bet_path = op.join(preproc_root, subject_01, 'anat', '{}_T1w'.format(subject_01))\n",
    "\n",
    "\n",
    "fast_target = bet_path # Replace with either anatomical_path or bet_path (note: you can try both and decide which is more reasonable!)\n",
    "\n",
    "[os.remove(f) for f in glob.glob(op.join(preproc_root, subject_01, 'anat', '*fast*'))] # Just to clean the directory in between runs of the cell\n",
    "segmentation_path = op.join(preproc_root, subject_01, 'anat', '{}_T1w_fast'.format(subject_01))\n",
    "fast(imgs=[fast_target], out=segmentation_path, n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02237126-915d-4c79-b78b-e2d02dd2abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(bet_path)\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_root, subject_01, 'anat','*pve_0*'))[0])\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_root, subject_01, 'anat','*pve_1*'))[0])\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_root, subject_01, 'anat','*pve_2*'))[0])\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[1]).cmap = 'Red'\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[2]).cmap = 'Green'\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[3]).cmap = 'Blue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a348af3-60b6-4aed-bff3-fec3705ce9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final result: \n",
      "0.003348 0.005721 -1.116064 204.794610 \n",
      "-0.933350 0.500887 0.005750 178.784833 \n",
      "0.501418 1.048657 -0.003251 -149.700516 \n",
      "0.000000 0.000000 0.000000 1.000000 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#________________LINEAR - COREGISTRATION | NORMALIZATION_____________________\n",
    "from fsl.wrappers import flirt\n",
    "\n",
    "\n",
    "subject_anatomical = op.join(preproc_root, subject_01, 'anat', '{}_T1w'.format(subject_01))\n",
    "mni_template = op.expandvars(op.join('$FSLDIR', 'data', 'standard', 'MNI152_T1_1mm_brain'))\n",
    "\n",
    "target = subject_anatomical # Fill me\n",
    "reference = mni_template # Fill me\n",
    "result = op.join(preproc_root, subject_01, 'anat', '{}_T1w_mni'.format(subject_01))\n",
    "flirt(target, reference, out=result)   # \"corratio\" est la loss fct utilisé par default ==> askip d'apres mes recherches adapté pour coregistration de T1 sur MNI template a voir si on veut changer....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a01aca6-3838-490b-984b-7aefc211c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(reference) \n",
    "fsleyesDisplay.load(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6476c0ae-b9a8-4ad2-902e-90d4d8b78a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#___________________________ fMRI PREPROCESSING __________________________________\n",
    "#on a fais le preprocessing sur les T1 file (antomical data) mtn on utilise ca pour le preprocessing sur les fMRI\n",
    "\n",
    "# STEP DONE ON T1 : \n",
    "#   - T1 skull-stripping (use BET)\n",
    "#   - T1 segmentation (use FAST)\n",
    "#   - Linare normalization of the T1 with MNI template\n",
    "\n",
    "subject_01 = 'sub-control01'\n",
    "# To have a quick view on the volumes\n",
    "run_of_interest = 1 # there are 1-5 runs of interest per subject\n",
    "fsleyesDisplay.resetOverlays()\n",
    "func_path = op.join(bids_root, subject_01, \"func\", \"{}_task-music_run-{}_bold.nii.gz\".format(subject_01,run_of_interest))\n",
    "fsleyesDisplay.load(func_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17a91438-dace-4df9-8761-7af33f4028c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the TR is: 3.0 secondes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find the TR in order to identify and keep the volumes of interest\n",
    "# JSON File containing metadata of the fMRIs\n",
    "json_file_path = op.join(bids_root,\"task-music_bold.json\")\n",
    "\n",
    "with open(json_file_path, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "if \"RepetitionTime\" in metadata:\n",
    "    tr_fmri = metadata[\"RepetitionTime\"]\n",
    "    print(f\"the TR is: {tr_fmri} secondes\")\n",
    "else:\n",
    "    print(\"TR not found.\")\n",
    "\n",
    "\n",
    "# ==> tr = 3 thus 1 volumes every 3 seconds\n",
    "# We will Remove the first volume (the first 3 seconds) of each \"tone\" phase in the fMRI analysis in order to: \n",
    "#       1) Stabilize the Hemodynamic Response: The initial volume, taken immediately after the start of a block, may capture a stabilizing BOLD signal rather than a stable, representative brain response to the stimulus. Removing this volume reduces the risk of including transient fluctuations, allowing you to focus on a more stable response.\n",
    "#       2) Avoid Transition Effects Between Blocks: Starting a new block can introduce transition or adjustment effects in the brain, especially if the preceding block involved a different task or condition. Removing the first volume helps minimize these potential transition effects or artifacts at the beginning of a new block.\n",
    "\n",
    "# _____________________!! JSP SI VOUS ETES DACCORD AVEC CA ?? - Mathieu !!_________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20dadc18-c428-426d-a7d4-91ed31df615f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    onset  duration      trial_type\n",
      "0     0.0      33.0           tones\n",
      "1    33.0       3.0        response\n",
      "2    36.0      31.5  negative_music\n",
      "3    67.5       3.0        response\n",
      "4    70.5      31.5           tones\n",
      "5   102.0       3.0        response\n",
      "6   105.0      31.5  positive_music\n",
      "7   136.5       3.0        response\n",
      "8   139.5      31.5           tones\n",
      "9   171.0       3.0        response\n",
      "10  174.0      31.5  negative_music\n",
      "11  205.5       3.0        response\n",
      "12  208.5      31.5           tones\n",
      "13  240.0       3.0        response\n",
      "14  243.0      31.5  positive_music\n",
      "15  274.5       3.0        response\n",
      "16  277.5      31.5           tones\n",
      "17  309.0       3.0        response\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tsv_file_path = \"ds000171/sub-control01/func/sub-control01_task-music_run-1_events.tsv\"\n",
    "table_of_times= pd.read_csv(tsv_file_path, sep='\\t')\n",
    "print(table_of_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909d3b8e-cf45-4fc5-9406-d26d2e365bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==> Tr = 3 \n",
    "# Run_time = 309 + 3 = 312s \n",
    "# ==> On a 105 volume (celui a t0 + les 312/3 suivants), ca correspond a ce qui est obtenu avec FSL quand on les display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0afdcbb6-efa5-4d44-8cb4-286115410e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tones : 0.0 - 11.0\n",
      "response : 11.0 - 12.0\n",
      "negative_music : 12.0 - 22.5\n",
      "response : 22.5 - 23.5\n",
      "tones : 23.5 - 34.0\n",
      "response : 34.0 - 35.0\n",
      "positive_music : 35.0 - 45.5\n",
      "response : 45.5 - 46.5\n",
      "tones : 46.5 - 57.0\n",
      "response : 57.0 - 58.0\n",
      "negative_music : 58.0 - 68.5\n",
      "response : 68.5 - 69.5\n",
      "tones : 69.5 - 80.0\n",
      "response : 80.0 - 81.0\n",
      "positive_music : 81.0 - 91.5\n",
      "response : 91.5 - 92.5\n",
      "tones : 92.5 - 103.0\n",
      "response : 103.0 - 104.0\n"
     ]
    }
   ],
   "source": [
    "tsv_file_path = \"ds000171/sub-control01/func/sub-control01_task-music_run-1_events.tsv\"\n",
    "TR = 3.0 \n",
    "table_of_times = pd.read_csv(tsv_file_path, sep='\\t')\n",
    "\n",
    "for _,row in table_of_times.iterrows():\n",
    "    onset = row['onset']\n",
    "    duration = row['duration']\n",
    "    trial_type = row['trial_type']\n",
    "    print(f\"{trial_type} : {onset / 3} - {onset /3 + duration /3}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe78403-c63e-4c0e-8faf-d962909d9122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
