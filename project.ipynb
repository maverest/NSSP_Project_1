{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca073aa5-9f61-4187-87e5-ded6ae9da786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 12:51:08.645: Failed to load module \"canberra-gtk-module\"\n"
     ]
    }
   ],
   "source": [
    "%gui wx\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#####################\n",
    "# Import of utils.py functions\n",
    "#####################\n",
    "# Required to get utils.py and access its functions\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('.')\n",
    "from utils import loadFSL, FSLeyesServer, mkdir_no_exist, interactive_MCQ\n",
    "\n",
    "os.environ[\"DIPY_HOME\"] = \"/home/jovyan/Data\"\n",
    "\n",
    "\n",
    "#############################\n",
    "# Loading fsl and freesurfer within Neurodesk\n",
    "# You can find the list of available other modules by clicking on the \"Softwares\" tab on the left\n",
    "#############################\n",
    "import lmod\n",
    "await lmod.purge(force=True)\n",
    "await lmod.load('fsl/6.0.7.4')\n",
    "await lmod.load('freesurfer/7.4.1')\n",
    "await lmod.list()\n",
    "\n",
    "####################\n",
    "# Setup FSL path\n",
    "####################\n",
    "loadFSL()\n",
    "\n",
    "###################\n",
    "# Load all relevant libraries for the lab\n",
    "##################\n",
    "import fsl.wrappers\n",
    "from fsl.wrappers import fslmaths\n",
    "\n",
    "import mne_nirs\n",
    "import nilearn\n",
    "from nilearn.datasets import fetch_development_fmri\n",
    "\n",
    "import mne\n",
    "import mne_nirs\n",
    "import dipy\n",
    "from dipy.data import fetch_bundles_2_subjects, read_bundles_2_subjects\n",
    "import xml.etree.ElementTree as ET\n",
    "import os.path as op\n",
    "import nibabel as nib\n",
    "import glob\n",
    "\n",
    "import ants\n",
    "\n",
    "import openneuro\n",
    "from mne.datasets import sample\n",
    "from mne_bids import BIDSPath, read_raw_bids, print_dir_tree, make_report\n",
    "\n",
    "\n",
    "# Useful imports to define the direct download function below\n",
    "import requests\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# FSL function wrappers which we will call from python directly\n",
    "from fsl.wrappers import fast, bet\n",
    "from fsl.wrappers.misc import fslroi\n",
    "from fsl.wrappers import flirt\n",
    "\n",
    "# General purpose imports to handle paths, files etc\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325abb6e-c9fd-40f2-96c0-865d93294e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:51:24: Debug: Adding duplicate image handler for 'Windows bitmap file'\n",
      "12:51:24: Debug: Adding duplicate animation handler for '1' type\n",
      "12:51:24: Debug: Adding duplicate animation handler for '2' type\n",
      "12:51:24: Debug: Adding duplicate image handler for 'Windows bitmap file'\n",
      "12:51:24: Debug: Adding duplicate animation handler for '1' type\n",
      "12:51:24: Debug: Adding duplicate animation handler for '2' type\n",
      "\n",
      "(ipykernel_launcher.py:1373): Gtk-CRITICAL **: 12:51:25.545: gtk_window_resize: assertion 'height > 0' failed\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# Start FSLeyes (very neat tool to visualize MRI data of all sorts) within Python\n",
    "################\n",
    "fsleyesDisplay = FSLeyesServer()\n",
    "fsleyesDisplay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76dbcbb-2593-4978-84bd-726929e97cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "dataset_id = \"ds000171\"\n",
    "bids_root = \"./ds000171\"  # Directory to store the downloaded dataset\n",
    "# Path to the 'derivatives' directory for processed data\n",
    "deriv_root = os.path.join(bids_root, 'derivatives')\n",
    "\n",
    "# Create a directory for preprocessed data (e.g., 'preprocessed_data')\n",
    "preproc_root = os.path.join(deriv_root, 'preprocessed_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27260a5-68e3-4732-bc69-d7e36a98d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create the target directory if it does not exist\n",
    "if not os.path.exists(bids_root):\n",
    "    os.makedirs(bids_root)\n",
    "\n",
    "# Download the raw data from OpenNeuro into the target directory\n",
    "#openneuro.download(dataset=dataset_id, target_dir= bids_root)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6803a6b3-e058-4884-a99c-bd11457e9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(preproc_root):\n",
    "    os.makedirs(preproc_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e17a849d-cae4-4c85-9ec0-1e9e00efe69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories created for processed data in ./ds000171/derivatives/preprocessed_data\n"
     ]
    }
   ],
   "source": [
    "subjects = [d for d in os.listdir(bids_root) if d.startswith('sub-con')]\n",
    "# Loop over all subjects and create directories for each subject's processed data\n",
    "for subject in subjects:\n",
    "    subject_dir = os.path.join(preproc_root, subject)\n",
    "\n",
    "    # Create subdirectories for anatomical and functional data\n",
    "    os.makedirs(os.path.join(subject_dir, 'anat'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(subject_dir, 'func'), exist_ok=True)\n",
    "\n",
    "print(f\"Directories created for processed data in {preproc_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e2858da-162d-4784-b3a7-9c31102c7e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oui\n"
     ]
    }
   ],
   "source": [
    "\n",
    "subjects = [d for d in os.listdir(bids_root) if d.startswith('sub-con')]\n",
    "anatomical_path = op.join(bids_root, subjects[0], 'anat', '{}_T1w.nii.gz'.format(subjects[0]))\n",
    "\n",
    "# Check if the anatomical file exists before calling BET\n",
    "if not os.path.exists(anatomical_path):\n",
    "    print(f\"Error: Anatomical file not found: {anatomical_path}\")\n",
    "else : \n",
    "    print(\"oui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0b7df63-ec80-4cdc-ad1d-9f7b92d3108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#________________________________ ANATOMICAL PREPROCESSING ____________________________________________\n",
    "subjects = [d for d in os.listdir(bids_root) if d.startswith('sub-con')]\n",
    "def get_skull_stripped_anatomical(bids_root, preproc_root, subject, robust=False):\n",
    "    \"\"\"\n",
    "    Function to perform skull-stripping (removing the skull around the brain).\n",
    "    This is a simple wrapper around the brain extraction tool (BET) in FSL's suite\n",
    "    It assumes data to be in the BIDS format (which we will cover in the following weeks).\n",
    "    The method also saves the brain mask which was used to extract the brain.\n",
    "\n",
    "    The brain extraction is conducted only on the T1w of the participant.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bids_root: string\n",
    "        The root of the BIDS directory\n",
    "    preproc_root: string\n",
    "        The root of the preprocessed data, where the result of the brain extraction will be saved.\n",
    "    subject_id: string\n",
    "        Subject ID, the subject on which brain extraction should be conducted.\n",
    "    robust: bool\n",
    "        Whether to conduct robust center estimation with BET or not. Default is False.\n",
    "    \"\"\"\n",
    "    anatomical_path = op.join(bids_root, subject, 'anat', '{}_T1w.nii.gz'.format(subject))\n",
    "    betted_brain_path = op.join(preproc_root, subject, 'anat', '{}_T1w'.format(subject))\n",
    "    os.system('bet {} {} -m {}'.format(anatomical_path, betted_brain_path, '-R' if robust else ''))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for sub in tqdm(subjects) : \n",
    "    #get_skull_stripped_anatomical(bids_root, preproc_root, sub, robust = True)\n",
    "\n",
    "#print(\"Done with BET.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "958e129d-e8f9-4776-999d-647a1acd7f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_01 = 'sub-control01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7d0d19b-fbd3-4f5c-9064-949b145a294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_skull_stripped_anatomical(bids_root, preproc_root, subject_01, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e4fefec-2d9a-4113-b618-7128d8612143",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(op.join(preproc_root, subject_01, 'anat', '{}_T1w.nii.gz'.format(subject_01)))\n",
    "fsleyesDisplay.load(resulting_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f5b2e12-7e9f-4c4a-adfd-fc277eb783dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#______________________TISSUE SEGMENTATION_______________\n",
    "\n",
    "anatomical_path = op.join(bids_root, subject_01, 'anat', '{}_T1w.nii.gz'.format(subject_01))\n",
    "bet_path = op.join(preproc_root, subject_01, 'anat', '{}_T1w'.format(subject_01))\n",
    "\n",
    "#########################\n",
    "# Solution\n",
    "# By reading above: we must apply FAST to the brain-extracted image. Thus we must use the BET path brain.\n",
    "##########################\n",
    "fast_target = bet_path # Replace with either anatomical_path or bet_path (note: you can try both and decide which is more reasonable!)\n",
    "\n",
    "[os.remove(f) for f in glob.glob(op.join(preproc_root, subject_01, 'anat', '*fast*'))] # Just to clean the directory in between runs of the cell\n",
    "segmentation_path = op.join(preproc_root, subject_01, 'anat', '{}_T1w_fast'.format(subject_01))\n",
    "fast(imgs=[fast_target], out=segmentation_path, n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02237126-915d-4c79-b78b-e2d02dd2abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(bet_path)\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_root, subject_01, 'anat','*pve_0*'))[0])\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_root, subject_01, 'anat','*pve_1*'))[0])\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_root, subject_01, 'anat','*pve_2*'))[0])\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[1]).cmap = 'Red'\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[2]).cmap = 'Green'\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[3]).cmap = 'Blue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a348af3-60b6-4aed-bff3-fec3705ce9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final result: \n",
      "0.003348 0.005721 -1.116064 204.794610 \n",
      "-0.933350 0.500887 0.005750 178.784833 \n",
      "0.501418 1.048657 -0.003251 -149.700516 \n",
      "0.000000 0.000000 0.000000 1.000000 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#________________COREGISTRATION_____________________\n",
    "from fsl.wrappers import flirt\n",
    "\n",
    "\n",
    "subject_anatomical = op.join(preproc_root, subject_01, 'anat', '{}_T1w'.format(subject_01))\n",
    "mni_template = op.expandvars(op.join('$FSLDIR', 'data', 'standard', 'MNI152_T1_1mm_brain'))\n",
    "\n",
    "###################\n",
    "# Select which image should be target or reference\n",
    "# ANSWER:\n",
    "# The subject anatomical will most often be the target, as the template is usually where we want to map our subjects for \n",
    "# group comparison.\n",
    "# There are cases, however, where we may want the subject anatomical to be the reference. This is the case when we want to map an \n",
    "# atlas to a subject while preserving the subject as much as possible.\n",
    "# We showcase here the case where the subject is chosen as target.\n",
    "##################\n",
    "target = subject_anatomical # Fill me\n",
    "reference = mni_template # Fill me\n",
    "result = op.join(preproc_root, subject_01, 'anat', '{}_T1w_mni'.format(subject_01))\n",
    "flirt(target, reference, out=result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a01aca6-3838-490b-984b-7aefc211c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(reference) \n",
    "fsleyesDisplay.load(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6476c0ae-b9a8-4ad2-902e-90d4d8b78a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
